Download Link: https://assignmentchef.com/product/solved-csci567-project-4-part1-hidden-markov-models
<br>
<h1 id="hidden-markov-models-50-points">Hidden Markov Models</h1>

In this programming assignment, we will implement Hidden Markov Models (HMM) and apply HMM to Part-of-Speech Tagging problem.

You need to first implement 6 important functions that help us accomplish various steps involved in learning HMM. Then you will be calculating HMM parameters from the data and use it to solve Part-of-Speech Tagging problem.

After finishing the implementation, you can use hmm_test_script.py to test the correctness of your functions.

There are 5 sets of grading data. Each grading data includes paramaters <code>(pi, A, B, obs_dict, state_dict, Osequence)</code> , which we will use to initialize HMM class and test your functions. To receive full credits, your output of function 1-5 should within an error of <span class="katex--inline"><span class="katex"><span class="katex-mathml">10^{-8}</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord">1</span><span class="mord">0<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−8</span></span></span></span></span></span></span></span></span></span></span></span>, your output of viterbi function should be identical with ours.

For the definitions of the parameters <code>pi</code>, <code>A</code>, <code>B</code> etc., please refer to the code documentation.

1.2 Application to Part-of-Speech Tagging

<ol>

 <li><code>model_training</code> – 10 = 10x(your_correct_pred_cnt/our_correct_pred_cnt)</li>

 <li><code>speech_tagging</code> – 10 = 10x(your_correct_pred_cnt/our_correct_pred_cnt)</li>

</ol>

We will use the dataset given to you for grading this part (with a different random seed). We will train your model and our model on same train_data. <code>model_training</code> function and <code>speech_tagging</code> function will be tested seperately.

In order to check your model_training function, we will use 50 sentences from <code>train_data</code> to do Part-of-Speech Tagging. To receive full credits, your prediction accuracy should be identical or better than ours.

In order to check your <code>speech_tagging</code> function, we will use 50 sentences from <code>test_data</code> to do Part-of-Speech Tagging. To receive full credits, your prediction accuracy should be identical or better than ours.

<h2 id="what-to-submit">What to submit</h2>

<ul>

 <li><a href="http://hmm.py">hmm.py</a></li>

 <li><a href="http://tagger.py">tagger.py</a></li>

</ul>

<h2 id="implementation-30-points">1.1 Implementation (30 points)</h2>

In 1.1, you are given parameters of a HMM and you will implement two procedures.

<ol>

 <li><strong>The Evaluation Problem</strong> : Given HMM Model and a sequence of observations, what is the probability that the observations are generated by the model?Two algorithms are usually used for the evaluation problem: forward algorithm or the backward algorithm. Based on the result of forward algorithm and backward algorithm, you will be asked to calculate probability of sequence and posterior probability of state.</li>

 <li><strong>The Decoding Problem</strong> : Given a model and a sequence of observations, what is the most likely state sequence in the model which produced the observation sequence. For decoding you will be implementing Viterbi algorithm.</li>

</ol>

<h3 id="hmm-class">HMM Class</h3>

In this project, we abstracted Hidden Markov Model as a class. Each Hiddern Markov Model initialized with <code>Pi, A, B, obs_dict</code> and <code>state_dict</code> . HMM class has 6 inner functions: <code>forward</code> function, <code>backward</code> function, <code>sequence_prob</code> function, <code>posterior_prob</code> function, <code>likelihood_prob</code> and <code>viterbi</code> function.

<pre><code>###You can add your ownfunction or variables in HMM class, but you shouldn 't change current existing api. ###class HMM:    def __init__(self, pi, A, B, obs_dict, state_dict):    -pi: (1 * num_state) A numpy array of initial probailities.pi[i] = P(X_1 = s_i) -    A: (num_state * num_state) A numpy array of transition probailities.A[i, j] = P(X_t = s_j | X_t - 1 = s_i) -    B: (num_state * num_obs_symbol) A numpy array of observation probabilities.B[i, o] = P(Z_t = z_o | X_t = s_i) -    obs_dict: A dictionary mapping each observation symbol to their index in B -    state_dict: A dictionary mapping each state to their index in pi and A    #TODO:    def forward(self, Osequence):    #TODO:    def backward(self, Osequence):    #TODO:    def sequence_prob(self, Osequence):    #TODO:    def posterior_prob(self, Osequence):    #TODO:    def likelihood_prob(self, Osequence):    #TODO:    def viterbi(self, Osequence):</code></pre>

<h3 id="evaluation-problem">1.1.1 Evaluation problem</h3>

<h4 id="a-forward-algorithm-and-backward-algorithm-10-points">(a) Forward algorithm and backward algorithm (10 points)</h4>

Here <span class="katex--inline"><span class="katex"><span class="katex-mathml">lambda</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">λ</span></span></span></span></span> means the model. Please finish the implementation of <code>forward()</code> function and <code>backward()</code> function in <a href="http://hmm.py">hmm.py</a>:

<ul>

 <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">alpha[i, t] = P(X_t = s_i, Z_{1:t} | lambda).</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></li>

</ul>

<pre><code>def forward(self, Osequence):    """Inputs:    -self.pi: (1 * num_state) A numpy array of initial probailities.pi[i] = P(X_1 = s_i) -    self.A: (num_state * num_state) A numpy array of transition probailities.A[i, j] = P(X_t = s_j | X_t - 1 = s_i) -    self.B: (num_state * num_obs_symbol) A numpy array of observation probabilities.B[i, o] = P(Z_t = z_o | X_t = s_i) -    Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -alpha: (num_state * L) A numpy array alpha[i, t] = P(X_t = s_i, Z_1: Z_t | λ)"""</code></pre>

<ul>

 <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">beta[i, t] = P(Z_{t+1: T}|X_t = s_i, lambda).</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">β</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span>1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></li>

</ul>

<pre><code>def backward(self, Osequence):    """Inputs:    -self.pi: (1 * num_state) A numpy array of initial probailities.pi[i] = P(X_1 = s_i) -    self.A: (num_state * num_state) A numpy array of transition probailities.A[i, j] = P(X_t = s_j | X_t - 1 = s_i) -    self.B: (num_state * num_obs_symbol) A numpy array of observation probabilities.B[i, o] = P(Z_t = z_o | X_t = s_i) -    Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -beta: (num_state * L) A numpy array beta[i, t] = P(Z_t + 1: Z_T | X_t = s_i, λ)"""</code></pre>

<h4 id="b-sequence-probability-2.5-points">(b) Sequence probability</h4>

Based on your forward and backward function, you will calculate the sequence probability. (You can call forward function or backward function inside of <code>sequence_prob</code> function)<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">P(Z_1, . . . , Z_T = O|lambda) = sum_{i=1}^{N}P(X_t = s_i, Z_{1: T} | lambda) = sum_{i=1}^{N}alpha[i, T]</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">T</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">O</span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span>1</span></span></span><span class=""><span class="mop op-symbol large-op">∑</span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">N</span></span></span></span></span><span class="vlist-s">​</span></span></span></span><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span>1</span></span></span><span class=""><span class="mop op-symbol large-op">∑</span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">N</span></span></span></span></span><span class="vlist-s">​</span></span></span></span><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">T</span><span class="mclose">]</span></span></span></span></span></span>

<pre><code>def sequence_prob(self, Osequence):    """Inputs:    -Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -prob: A float number of P(Z_1: Z_T | λ)"""</code></pre>

<h4 id="c-posterior-probability-5-points">( c) Posterior probability</h4>

The forward variable <span class="katex--inline"><span class="katex"><span class="katex-mathml">alpha[i, t]</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span></span></span></span></span> and backward variable <span class="katex--inline"><span class="katex"><span class="katex-mathml">beta[i, t]</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">β</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span></span></span></span></span> are used to calculate the posterior probability of a specific state. Now for <span class="katex--inline"><span class="katex"><span class="katex-mathml">t = 1ldots T</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">t</span><span class="mrel">=</span></span><span class="base"><span class="mord">1</span><span class="minner">…</span><span class="mord mathdefault">T</span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml">i = 1ldots N</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">i</span><span class="mrel">=</span></span><span class="base"><span class="mord">1</span><span class="minner">…</span><span class="mord mathdefault">N</span></span></span></span></span>, we define posterior probability <span class="katex--inline"><span class="katex"><span class="katex-mathml">gamma_t(i) = P(X_t = s_i|O, lambda)</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">O</span><span class="mpunct">,</span><span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span></span></span> the probability of being in state <span class="katex--inline"><span class="katex"><span class="katex-mathml">s_i</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span></span></span></span></span> at time t given the observation sequence O and the model <span class="katex--inline"><span class="katex"><span class="katex-mathml">lambda</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">λ</span></span></span></span></span>.

<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">gamma_t(i) = frac{P(X_t = s_i, O|lambda)}{P(O|lambda)} = frac{P(X_t = s_i, Z_{1:t}|lambda)}{P(O|lambda)}</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">O</span>∣<span class="mord mathdefault">λ</span><span class="mclose">)</span></span><span class=""><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">X</span><span class="msupsub"><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span><span class="vlist-s">​</span></span><span class="mrel">=</span><span class="mord mathdefault">s</span><span class="msupsub"><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span><span class="vlist-s">​</span></span><span class="mpunct">,</span><span class="mord mathdefault">O</span>∣<span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">O</span>∣<span class="mord mathdefault">λ</span><span class="mclose">)</span></span><span class=""><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">X</span><span class="msupsub"><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span><span class="vlist-s">​</span></span><span class="mrel">=</span><span class="mord mathdefault">s</span><span class="msupsub"><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span><span class="vlist-s">​</span></span><span class="mpunct">,</span><span class="mord mathdefault">Z</span><span class="msupsub"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span></span></span><span class="vlist-s">​</span></span>∣<span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span><span class="vlist-s">​</span></span></span></span></span></span></span></span></span></span>

<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">P(X_t = s_i, Z_{1:t}|lambda) = P(Z_{1:t}|X_t = s_i, lambda) cdot P(Z_{t+1: T}|X_t = s_i, lambda) cdot P(X_t = s_i|lambda) = alpha[i, t] cdot beta[i, t]</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mbin">⋅</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span>1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mbin">⋅</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span><span class="mbin">⋅</span></span><span class="base"><span class="mord mathdefault">β</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span></span></span></span></span></span>Thus

<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">gamma_t(i) = frac{alpha[i, t] cdot beta[i, t]}{P(O|lambda)}</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">O</span>∣<span class="mord mathdefault">λ</span><span class="mclose">)</span></span><span class=""><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span><span class="mbin">⋅</span><span class="mord mathdefault">β</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">t</span><span class="mclose">]</span></span></span><span class="vlist-s">​</span></span></span></span></span></span></span></span></span></span>where

<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">P(O|lambda) = sum_{i=1}^{N}alpha[i, T]</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord mathdefault">O</span><span class="mord">∣</span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span>1</span></span></span><span class=""><span class="mop op-symbol large-op">∑</span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">N</span></span></span></span></span><span class="vlist-s">​</span></span></span></span><span class="mord mathdefault">α</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mord mathdefault">T</span><span class="mclose">]</span></span></span></span></span></span>Signature:

<pre><code>def posterior_prob(self, Osequence):    """Inputs:    -Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -prob: (num_state * L) A numpy array of P(X_t = i | O, λ)"""</code></pre>

You can use <span class="katex--inline"><span class="katex"><span class="katex-mathml">beta_t(i)</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span></span> to find the most likely state at time t which is the state <span class="katex--inline"><span class="katex"><span class="katex-mathml">Z_t=s_i</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span></span></span></span></span></span></span></span> for which <span class="katex--inline"><span class="katex"><span class="katex-mathml">beta_t(i)</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span></span> is maximum. This algorithm works fine in the case when HMM is ergodic i.e. there is transition from any state to any other state. If applied to an HMM of another architecture, this approach could give a sequence that may not be a legitimate path because some transitions are not permitted. To avoid this problem Viterbi algorithm is the most common decoding algorithms used.

<h4 id="d-likelihood-of-two-consecutive-states-at-a-given-time-5-points">(d) Likelihood of two consecutive states at a given time (5 points)</h4>

You are required to calculate the likelihood of transition from state <span class="katex--inline"><span class="katex"><span class="katex-mathml">s</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">s</span></span></span></span></span> at time <span class="katex--inline"><span class="katex"><span class="katex-mathml">t</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">t</span></span></span></span></span> to state <span class="katex--inline"><span class="katex"><span class="katex-mathml">s’</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> at time <span class="katex--inline"><span class="katex"><span class="katex-mathml">t+1</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord mathdefault">t</span><span class="mbin">+</span></span><span class="base"><span class="mord">1</span></span></span></span></span>. That is, you’re required to calculate<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">xi_{s, s’} (t) = P(X_t=s, X_{t+1}=s’  | Z_{1: T} = z_{1: T})</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">ξ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">s</span><span class="vlist-t"><span class="sizing reset-size3 size1 mtight">′</span></span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span>1</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord">∣</span><span class="mspace"> </span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord"><span class="mord mathdefault">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1<span class="mrel mtight">:</span><span class="mord mathdefault mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span>Signature:

<pre><code>def likelihood_prob(self, Osequence):    """Inputs:    -Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -prob: (num_state * (L - 1)) A numpy array of P(X_t = i, X_t + 1 = j | O, λ)"""</code></pre>

<h4 id="e-viterbi-algorithm-7.5-points">(e) Viterbi algorithm (7.5 points)</h4>

Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states. We want to compute the most likely state path that corresponds to the observation sequence O based HMM. Namely, <span class="katex--inline"><span class="katex"><span class="katex-mathml">k^∗ = (k^∗_1, k^∗_2, ··· , k^∗_T) = textrm{arg}max_k P(s_{k_1}, s_{k_2}, ··· , s_{k_T}|Z_1, Z_2, ··· , Z_T = O, lambda)</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="mord mathdefault">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">T</span></span></span><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mclose">)</span><span class="mrel">=</span></span><span class="base"><span class="mord text"><span class="mord textrm">arg</span></span><span class="mop">max<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">k</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord mathdefault">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">k</span><span class="sizing reset-size3 size1 mtight">1</span><span class="vlist-s">​</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">k</span><span class="sizing reset-size3 size1 mtight">2</span><span class="vlist-s">​</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">k</span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">T</span></span><span class="vlist-s">​</span></span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mpunct">,</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">⋅</span><span class="mpunct">,</span><span class="mord"><span class="mord mathdefault">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">T</span></span></span></span><span class="vlist-s">​</span></span></span></span></span><span class="mrel">=</span></span><span class="base"><span class="mord mathdefault">O</span><span class="mpunct">,</span><span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span></span></span>.

Signature:

<pre><code>def viterbi(self, Osequence):    """Inputs:    -Osequence: (1 * L) A numpy array of observation sequence with length LReturns:    -path: A List of the most likely hidden state path k * (        return state instead of idx)"""</code></pre>

<h2 id="application-to-speech-tagging--20-points">1.2 Application to Speech Tagging</h2>

Part-of-Speech (POS) is a category of words (or, more generally, of lexical items) which have similar grammatical properties. (Example: noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, and sometimes numeral, article, or determiner.)

Part-of-Speech Tagging (POST) is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context.

Here you wiil use HMM to do POST. You will need to calculate the parameters <code>(pi, A, B, obs_dict, state_dict)</code> of HMM first and then apply Viterbi algorithm to do speech-tagging.

<h3 id="dataset">Dataset</h3>

tags.txt: Universal Part-of-Speech Tagset

<table>

 <thead>

  <tr>

   <th align="left">Tag</th>

   <th align="left">Meaning</th>

   <th align="left">English Examples</th>

  </tr>

 </thead>

 <tbody>

  <tr>

   <td align="left">ADJ</td>

   <td align="left">adjective</td>

   <td align="left">new, good, high, special, big, local</td>

  </tr>

  <tr>

   <td align="left">ADP</td>

   <td align="left">adposition</td>

   <td align="left">on, of, at, with, by, into, under</td>

  </tr>

  <tr>

   <td align="left">ADV</td>

   <td align="left">adverb</td>

   <td align="left">really, already, still, early, now</td>

  </tr>

  <tr>

   <td align="left">CONJ</td>

   <td align="left">conjunction</td>

   <td align="left">and, or, but, if, while, although</td>

  </tr>

  <tr>

   <td align="left">DET</td>

   <td align="left">determiner, article</td>

   <td align="left">the, a, some, most, every, no, which</td>

  </tr>

  <tr>

   <td align="left">NOUN</td>

   <td align="left">noun</td>

   <td align="left">year, home, costs, time, Africa</td>

  </tr>

  <tr>

   <td align="left">NUM</td>

   <td align="left">numeral</td>

   <td align="left">twenty-four, fourth, 1991, 14:24</td>

  </tr>

  <tr>

   <td align="left">PRT</td>

   <td align="left">particle</td>

   <td align="left">at, on, out, over per, that, up, with</td>

  </tr>

  <tr>

   <td align="left">PRON</td>

   <td align="left">pronoun</td>

   <td align="left">he, their, her, its, my, I, us</td>

  </tr>

  <tr>

   <td align="left">VERB</td>

   <td align="left">verb</td>

   <td align="left">is, say, told, given, playing, would</td>

  </tr>

  <tr>

   <td align="left">.</td>

   <td align="left">punctuation marks</td>

   <td align="left">. , ; !</td>

  </tr>

  <tr>

   <td align="left">X</td>

   <td align="left">other</td>

   <td align="left">ersatz, esprit, dunno, gr8, univeristy</td>

  </tr>

 </tbody>

</table>

sentences.txt: Including 57340 sentences which have already been tagged.

<table>

 <thead>

  <tr>

   <th align="center">Word</th>

   <th align="center">Tag</th>

  </tr>

 </thead>

 <tbody>

  <tr>

   <td align="center">b100-48585</td>

   <td align="center"></td>

  </tr>

  <tr>

   <td align="center">She</td>

   <td align="center">PRON</td>

  </tr>

  <tr>

   <td align="center">had</td>

   <td align="center">VERB</td>

  </tr>

  <tr>

   <td align="center">to</td>

   <td align="center">PRT</td>

  </tr>

  <tr>

   <td align="center">move</td>

   <td align="center">VERB</td>

  </tr>

  <tr>

   <td align="center">in</td>

   <td align="center">ADP</td>

  </tr>

  <tr>

   <td align="center">some</td>

   <td align="center">DET</td>

  </tr>

  <tr>

   <td align="center">direction</td>

   <td align="center">NOUN</td>

  </tr>

  <tr>

   <td align="center">–</td>

   <td align="center">.</td>

  </tr>

  <tr>

   <td align="center">any</td>

   <td align="center">DET</td>

  </tr>

  <tr>

   <td align="center">direction</td>

   <td align="center">NOUN</td>

  </tr>

  <tr>

   <td align="center">that</td>

   <td align="center">PRON</td>

  </tr>

  <tr>

   <td align="center">would</td>

   <td align="center">VERB</td>

  </tr>

  <tr>

   <td align="center">take</td>

   <td align="center">VERB</td>

  </tr>

  <tr>

   <td align="center">her</td>

   <td align="center">PRON</td>

  </tr>

  <tr>

   <td align="center">away</td>

   <td align="center">ADV</td>

  </tr>

  <tr>

   <td align="center">from</td>

   <td align="center">ADP</td>

  </tr>

  <tr>

   <td align="center">this</td>

   <td align="center">DET</td>

  </tr>

  <tr>

   <td align="center">evil</td>

   <td align="center">ADJ</td>

  </tr>

  <tr>

   <td align="center">place</td>

   <td align="center">NOUN</td>

  </tr>

  <tr>

   <td align="center">.</td>

   <td align="center">.</td>

  </tr>

 </tbody>

</table>

<h3 id="part-of-speech-tagging">Part-of-Speech Tagging</h3>

In this part, we collect our dataset and tags with Dataset class. Dataset class includes tags, train_data and test_data. In both dataset include a list of sentences, each sentence is an object of Line class.

You only need to implement <code>model_training</code> function and <code>speech_tagging</code> function. We have provided the accuracy function, which you can use to compare your <code>predict_tagging</code> and <code>true_tagging</code> of a sentence. You can find the definition below.

<pre><code>###You can add your own functions or variables in Dataset class, but you shouldn 't change current functions that exist. ###class Dataset:    def __init__(self, tagfile, datafile, train_test_split = 0.8, seed = 112890):    self.tagsself.train_dataself.test_datadef read_data(self, filename):    def read_tags(self, filename):    class Line:    def __init__(self, line, type):    self.idself.wordsself.tagsself.lengthdef show(self): #TODO:    def model_training(train_data, tags)# TODO:    def Speech_tagging(model, test_data, tags)def accuracy(predict_tagging, true_tagging)</code></pre>

<h3 id="model-training-10-points">1.2.1 Model training (10 points)</h3>

In this part, you will need to calculate the parameters of HMM model based on <code>train_data</code> .

Signature:

<pre><code>def model_training(train_data, tags):    """Inputs:    -train_data: a list of sentences, each sentence is an object of Line class -    tags: a list of POS tagsReturns:    -model: an object of HMM class initialized with paramaters(pi, A, B, obs_dict, state_dict) you calculated based on traning dataset.We will use the object you returned to do speech tagging.    ""    "</code></pre>

<h3 id="speech_tagging-10-points">1.2.2 Speech_tagging (10 points)</h3>

Based on HMM from 2.2.1, do speech tagging for each sentence on test data. Note when you meet a word which is unseen in training dataset. You need to modify the emission matrix and obs_dict of your current model in order to handle this case. You will assume the emission probability from each state to a new unseen word is <span class="katex--inline"><span class="katex"><span class="katex-mathml">10^{-6}</span><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord">1</span><span class="mord">0<span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist"><span class=""><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">−6</span></span></span></span></span></span></span></span></span></span></span></span>(a very low probability).

<pre><code>For example, in hmm_model.json, we use the following paramaters to initialize HMM:    S = ["1", "2"]pi: [0.7, 0.3]A: [    [0.8, 0.2],    [0.4, 0.6]]B = [    [0.5, 0, 0.4, 0.1],    [0.5, 0.1, 0.2, 0.2]]Observations = ["A", "C", "G", "T"]If we find another observation symbol "X" in observation sequence, we will modify parameters of HMM as follows:    S = ["1", "2"]pi: [0.7, 0.3]A: [    [0.8, 0.2],    [0.4, 0.6]]B = [    [0.5, 0, 0.4, 0.1, 1e-6],    [0.5, 0.1, 0.2, 0.2, 1e-6]]Observations = ["A", "C", "G", "T", "X"]</code></pre>

You do not get access to <code>test_data</code> on <code>model_training</code> function, you need to implement the logic to tag a new sequence in <code>speech_tagging</code> function.

Signature:

<pre><code>def speech_tagging(test_data, model):    """Inputs:    -test_data: (1 * num_sentence) a list of sentences, each sentence is an object of Line class -    model: an object of HMM classReturns:    -tagging: (num_sentence * num_tagging) a 2 D list of output taggingfor each sentences on test_data    """</code></pre>

<h3 id="suggestion0-points">1.2.3 Suggestion(0 points)</h3>

This part won’t be graded. In order to have a better understanding of HMM. Come up with one sentence by yourself and tagging it manually. Then run your forward function, backward function, <code>seq_prob</code> function, <code>posterior_prob</code> function and viterbi function on the model from 2.2.1. Print the result of each function, see if you can explain your result.